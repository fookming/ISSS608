{
  "hash": "b180a1d8a632462c77a3730359703dc9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take Home Exercise 3 (Work in progress... )\"\nauthor: \"Ee Fook Ming\"\ndate: \"March 22, 2025\"\ndate-modified: last-modified\ncode-fold: true\ncode-summary: \"Show the code\"\nexecute:\n  echo: true\n  eval: true\n  warning: false\n  message: false\n  freeze: true\n  fig-width: 12\n  fig-height: 8\nformat: \n  html:\n    number-sections: true\n#    number-offset: [26, 0]  # Offset heading levels by starting at 27\noutput: \n  html_document: \n    toc: true\n    tabset: true\n---\n\n\n\n# Introduction\n\nSingapore’s high temperatures, intense rainfall, and humidity create substantial challenges across industries that depend on reliable, data-driven weather insights. Although current dashboards typically provide only elementary observations, there is a clear need for a more comprehensive, analytics-focused platform. By incorporating in-depth statistical methods, spatial visualizations, and predictive modeling capabilities, such a solution can empower businesses, researchers, and policymakers to anticipate weather-induced risks, manage resources, and make informed decisions.\n\nFor **Take-home Exercise 3**, I will concentrate on **Time Series Analysis & Forecasting** as a key prototyping requirement, covering the following aspects:\n\n-   **Trend & Seasonality Detection**: Analyzing long-term variations and seasonal cycles through rolling averages and plot-based approaches.\n-   **Time Series Decomposition**: Employing methods (e.g., STL) to separate out trend, seasonality, and residual components.\n-   **Statistical Analysis of Weather Patterns**: Computing essential metrics (mean shifts, variance changes) to assess fluctuations in temperature, rainfall, and wind.\n-   **Forecasting Future Trends**: Utilizing models such as ARIMA, Prophet, or Exponential Smoothing to project weather conditions and evaluate potential climate risks.\n\nBy integrating these methods, the platform aims to offer robust, standalone analytics that serve a diverse set of needs—ranging from urban planning and infrastructure maintenance to insurance and agricultural operations—ultimately promoting greater climate resilience in Singapore.\n\n# Data Preparation & Processing\n\n## Loading Libraries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(httr, readxl, dplyr, readr, openxlsx, zoo)\n```\n:::\n\n\n\n-   [**httr**](https://httr.r-lib.org/) simplifies the process of making HTTP requests in R, useful for accessing web APIs and retrieving online data sources programmatically.\n-   [**readxl**](https://readxl.tidyverse.org/) enables easy importing and reading of Excel files (.xls, .xlsx) directly into R, facilitating straightforward integration of spreadsheet data into data analysis workflows.\n-   [**dplyr**](https://readr.tidyverse.org/) offers a robust and intuitive grammar for data manipulation, making tasks like filtering, grouping, summarizing, and mutating data straightforward and efficient.\n-   [**readr**](https://readr.tidyverse.org/) simplifies the process of importing flat files, including CSV and TSV formats, with optimized performance and ease of use.\n-   [**openxlsx**](https://ycphs.github.io/openxlsx/) provides efficient functions for reading, writing, and editing Excel files (.xlsx) from within R without the need for external software dependencies like Java.\n-   [**zoo**](https://cran.r-project.org/web/packages/zoo/index.html) offers infrastructure for regular and irregular time series data, providing versatile methods for manipulating and analyzing ordered observations.\n\n## Scrape Climate Historical Records (www.weather.gov.sg)\n\n### Retrieve Station Codes\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstation_records <- read_excel(\"data/Station_Records.xlsx\")\n\n# Obtain a list of station codes\nstation_name <- station_records$`station`\nstation_codes <- station_records$`code`\nstation_type <- station_records$`type`\n\nprint(station_codes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"S104\" \"S105\" \"S109\" \"S86\"  \"S63\"  \"S120\" \"S55\"  \"S64\"  \"S90\"  \"S92\" \n[11] \"S61\"  \"S24\"  \"S114\" \"S121\" \"S11\"  \"S50\"  \"S118\" \"S107\" \"S39\"  \"S101\"\n[21] \"S44\"  \"S117\" \"S33\"  \"S31\"  \"S71\"  \"S122\" \"S66\"  \"S112\" \"S08\"  \"S07\" \n[31] \"S40\"  \"S108\" \"S113\" \"S111\" \"S119\" \"S116\" \"S29\"  \"S94\"  \"S06\"  \"S106\"\n[41] \"S81\"  \"S77\"  \"S25\"  \"S102\" \"S80\"  \"S60\"  \"S36\"  \"S110\" \"S84\"  \"S79\" \n[51] \"S43\"  \"S78\"  \"S72\"  \"S23\"  \"S88\"  \"S89\"  \"S115\" \"S82\"  \"S35\"  \"S69\" \n[61] \"S46\"  \"S123\" \"S91\" \n```\n\n\n:::\n\n```{.r .cell-code}\nprint(station_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"Full AWS Station\" \"Closed Station\"   \"Full AWS Station\" \"Closed Station\"  \n [5] \"Closed Station\"   \"Rainfall Station\" \"Closed Station\"   \"Rainfall Station\"\n [9] \"Rainfall Station\" \"Rainfall Station\" \"Closed Station\"   \"Full AWS Station\"\n[13] \"Rainfall Station\" \"Full AWS Station\" \"Closed Station\"   \"Full AWS Station\"\n[17] \"Closed Station\"   \"Full AWS Station\" \"Closed Station\"   \"Closed Station\"  \n[21] \"Full AWS Station\" \"Full AWS Station\" \"Rainfall Station\" \"Closed Station\"  \n[25] \"Rainfall Station\" \"Closed Station\"   \"Rainfall Station\" \"Rainfall Station\"\n[29] \"Rainfall Station\" \"Rainfall Station\" \"Rainfall Station\" \"Full AWS Station\"\n[33] \"Rainfall Station\" \"Full AWS Station\" \"Rainfall Station\" \"Full AWS Station\"\n[37] \"Rainfall Station\" \"Rainfall Station\" \"Full AWS Station\" \"Full AWS Station\"\n[41] \"Rainfall Station\" \"Rainfall Station\" \"Full AWS Station\" \"Full AWS Station\"\n[45] \"Full AWS Station\" \"Full AWS Station\" \"Rainfall Station\" \"Closed Station\"  \n[49] \"Rainfall Station\" \"Rainfall Station\" \"Full AWS Station\" \"Rainfall Station\"\n[53] \"Closed Station\"   \"Full AWS Station\" \"Rainfall Station\" \"Rainfall Station\"\n[57] \"Full AWS Station\" \"Closed Station\"   \"Closed Station\"   \"Closed Station\"  \n[61] \"Closed Station\"   \"Closed Station\"   \"Closed Station\"  \n```\n\n\n:::\n:::\n\n\n\nThe code chunk retrieves station codes and their corresponding types. These codes form part of a text string used to construct hyperlinks, which retrieve data directly from the weather website. There are three station types:\n\n-   **Full AWS station:** collects weather data on rainfall, temperature, and wind.\n-   **Rainfall station:** collects rainfall data only.\n-   **Closed station:** a station that is no longer operational.\n\nThese station identifiers are useful for data filtering, analysis, and visualization based on specific station characteristics.\n\n### Scrape the Actual Data from Website - (2018 to 2024)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(httr)\nlibrary(readr)\nlibrary(dplyr)\n\n# Set base URL template and save file path\nbase_url_template <- \"http://www.weather.gov.sg/files/dailydata/DAILYDATA_%s_%d%s.csv\"\nsave_file <- \"data/Climate_Data_2018_2024.csv\"\ndir.create(dirname(save_file), recursive = TRUE, showWarnings = FALSE)\n\n# Define expected column names (preserve exact spacing)\ncolumn_names <- c(\n  \"Station\", \"Year\", \"Month\", \"Day\", \n  \"Daily Rainfall Total (mm)\", \"Highest 30 min Rainfall (mm)\", \n  \"Highest 60 min Rainfall (mm)\", \"Highest 120 min Rainfall (mm)\", \n  \"Mean Temperature (Celsius)\", \"Maximum Temperature (Celsius)\", \n  \"Minimum Temperature (Celsius)\", \"Mean Wind Speed (km/h)\", \n  \"Max Wind Speed (km/h)\"\n)\n\n# Ensure CSV file has proper headers only if it does not exist\nif (!file.exists(save_file)) {\n  write_csv(as.data.frame(matrix(ncol = length(column_names), nrow = 0, dimnames = list(NULL, column_names))), \n            save_file)\n}\n\n# Function to download and append data\ndownload_and_append <- function(station_code, year, month) {\n  month_str <- sprintf(\"%02d\", month)  # Format month as \"01\", \"02\", etc.\n  file_url <- sprintf(base_url_template, station_code, year, month_str)\n\n  # Attempt to download file\n  response <- tryCatch({\n    GET(file_url)\n  }, error = function(e) {\n    message(sprintf(\"Error fetching: %s\", file_url))\n    return(NULL)\n  })\n\n  # Skip if download failed\n  if (is.null(response) || status_code(response) != 200) {\n    message(sprintf(\"Skipping failed download: %s\", file_url))\n    return()\n  }\n\n  # Attempt to read the CSV content\n  csv_data <- tryCatch({\n    read_csv(content(response, \"raw\"), show_col_types = FALSE, col_names = FALSE, skip = 1)\n  }, error = function(e) {\n    message(sprintf(\"Failed to read CSV: %s\", file_url))\n    return(NULL)\n  })\n\n  # Skip if data is invalid\n  if (is.null(csv_data) || ncol(csv_data) != length(column_names)) {\n    message(sprintf(\"Skipping invalid dataset: %s\", file_url))\n    return()\n  }\n\n  # Assign column names\n  colnames(csv_data) <- column_names  \n\n  # Remove rows where all values (except \"Station\", \"Year\", \"Month\", \"Day\") are NA, empty, or \"-\"\n  csv_data <- csv_data %>%\n    filter(!if_all(-c(1:4), ~ is.na(.) | . == \"\" | . == \"-\"))\n\n  # Skip if dataset is still empty after filtering\n  if (nrow(csv_data) == 0) {\n    message(sprintf(\"Skipping empty dataset: %s\", file_url))\n    return()\n  }\n\n  # Append valid data\n  write_csv(csv_data, save_file, append = TRUE)  \n  message(sprintf(\"Appended data for %s - %d-%s\", station_code, year, month_str))\n}\n\n# Loop through each station code and fetch data\nfor (station_code in station_codes) {\n  for (year in 2018:2024) {\n    for (month in 1:12) {\n      download_and_append(station_code, year, month)\n    }\n  }\n}\n\nprint(\"Download process completed for all stations.\")\n```\n:::\n\n\n\nThe code chunk systematically downloads daily climate data from Singapore's weather service for multiple weather stations, covering years 2018 through 2024. It constructs URLs dynamically based on station codes, year, and month, retrieves CSV files, filters out incomplete or invalid entries, and then consolidates valid data into a single CSV file (`Climate_Data_2018_2024.csv`). The primary intention is to compile a structured, comprehensive dataset of climate measurements for subsequent analysis or visualization tasks.\n\n### Filtered Data for All Weather Stations (AWS)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(readr)\n\n# Read station records and climate data\nstation_records <- read_excel(\"data/Station_Records.xlsx\")\nclimate_data <- read_csv(\"data/Climate_Data_2018_2024.csv\")\n\n# Filter stations with type \\\"Full AWS Station\\\"\nfull_aws_stations <- station_records %>%\n  filter(type == \"Full AWS Station\") %>%\n  pull(station)\n\n# Filter climate data to include only Full AWS Stations\nfiltered_climate_data <- climate_data %>%\n  filter(Station %in% full_aws_stations)\n\n# Check the results\n# head(filtered_climate_data)\n\n# Save the filtered data\nwrite_csv(filtered_climate_data, \"data/Climate_Data_2018_2024_AWS.csv\")\n```\n:::\n\n\n\nThe project is interested only in AWS (All Weather Stations).\n\n### Removed Special Character and Replaced with NA\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\n\n# Read CSV file (all columns initially as character)\nclimate_data <- read_csv(\"data/Climate_Data_2018_2024_AWS.csv\", \n                         col_types = cols(.default = \"c\"),\n                         locale = locale(encoding = \"UTF-8\"))\n\n# Columns to convert safely to numeric\nnumeric_columns <- c(\"Daily Rainfall Total (mm)\",\n                     \"Highest 30 min Rainfall (mm)\",\n                     \"Highest 60 min Rainfall (mm)\",\n                     \"Highest 120 min Rainfall (mm)\",\n                     \"Mean Temperature (Celsius)\",\n                     \"Maximum Temperature (Celsius)\",\n                     \"Minimum Temperature (Celsius)\",\n                     \"Mean Wind Speed (km/h)\",\n                     \"Max Wind Speed (km/h)\")\n\n# Clean problematic multibyte strings and convert to numeric\nclimate_data_clean <- climate_data %>%\n  mutate(across(all_of(numeric_columns), ~str_replace_all(., \"[^0-9\\\\.\\\\-]\", \"\"))) %>%\n  mutate(across(all_of(numeric_columns), ~as.numeric(.)))\n\n# Save cleaned data\nwrite_csv(climate_data_clean, \"data/Climate_Data_2018_2024_AWS_Cleaned.csv\")\n```\n:::\n\n\n\nThe code chunk removes special characters from the source file because they cause run-time errors during subsequent processing.\n\n### Impute Missing Data (field with NA) using Simple Moving Average 5-Day Rolling\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(dplyr)\nlibrary(openxlsx)\n\n# === Load dataset ===\nclimate <- read_csv(\"data/Climate_Data_2018_2024_AWS_Cleaned.csv\")\noriginal <- climate\n\n# Columns to impute\n\nimpute_cols <- c(\"Daily Rainfall Total (mm)\",\n                     \"Highest 30 min Rainfall (mm)\",\n                     \"Highest 60 min Rainfall (mm)\",\n                     \"Highest 120 min Rainfall (mm)\",\n                     \"Mean Temperature (Celsius)\",\n                     \"Maximum Temperature (Celsius)\",\n                     \"Minimum Temperature (Celsius)\",\n                     \"Mean Wind Speed (km/h)\",\n                     \"Max Wind Speed (km/h)\")\n\n\n# === Backward SMA-5 for first 4 rows ===\nfor (i in 4:1) {\n  window <- climate[(i + 1):(i + 5), impute_cols]\n  sma_values <- colMeans(window, na.rm = TRUE) %>% round(1)\n  climate[i, impute_cols] <- as.list(sma_values)\n}\n\n# === Forward SMA-5 for all other NAs ===\nfor (col in impute_cols) {\n  na_indices <- which(is.na(climate[[col]]))\n  for (idx in na_indices) {\n    if (idx >= 6) {  # start from the 6th row to ensure a 5-day window\n      window_vals <- climate[[col]][(idx - 5):(idx - 1)]\n      if (all(is.na(window_vals))) {\n        next  # skip if all previous 5 rows are NA, to prevent infinite loop\n      }\n      sma_val <- mean(window_vals, na.rm = TRUE) %>% round(1)\n      climate[[col]][idx] <- sma_val\n    }\n  }\n}\n\n# === Save updated CSV ===\nwrite_csv(climate,\"data/Climate_Final_2018_2024.csv\")\n\n# === Prepare Excel with bold + red styling for updated NA values ===\nwb <- createWorkbook()\naddWorksheet(wb, \"Updated_NAs\")\n\n# Red bold style\nstyle_red_bold <- createStyle(textDecoration = \"bold\", fontColour = \"#FF0000\")\n\n# Write dataset with header row\nwriteData(wb, \"Updated_NAs\", climate, startRow = 1, colNames = TRUE)\n\n# Efficiently apply styles to updated cells only\nfor (col_name in impute_cols) {\n  col_idx <- which(names(climate) == col_name)\n  updated_rows <- which(is.na(original[[col_name]]) & !is.na(climate[[col_name]]))\n  \n  if (length(updated_rows) > 0) {\n    # Batch style application for performance\n    addStyle(wb,\n             sheet = \"Updated_NAs\",\n             style = style_red_bold,\n             rows = updated_rows + 1,  # Offset +1 due to header row\n             cols = rep(col_idx, length(updated_rows)),\n             gridExpand = FALSE,\n             stack = TRUE)\n  }\n}\n\n# Save Excel\nsaveWorkbook(wb, \"data/NAs_fields_updated_5-Day.xlsx\", overwrite = TRUE)\n```\n:::\n\n\n\nThe code chunk above performs data cleaning and imputation on a climate dataset by applying a 5-day Simple Moving Average (SMA-5) to fill missing values in selected weather metrics. Initially, it uses a backward SMA-5 approach to estimate missing data for the first four rows. Subsequently, a forward SMA-5 method is applied to impute missing values throughout the remaining dataset. Additionally, the code highlights imputed values by highlighting them in bold red within an Excel workbook, making the updates clearly identifiable.\n\n# Time Series Analysis and Forecast\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Import Data & Preparation\n\n# Read the data\nweather_data <- read_csv(\"data/Climate_Final_2018_2024.csv\")\n\n# Combine Year, Month, and Day into a single date column\nweather_ts <- weather_data %>%\n  mutate(date = make_date(Year, Month, Day)) %>%\n  select(Station, date, everything(), -Year, -Month, -Day)\n\n# Inspect data\nhead(weather_ts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 11\n  Station   date       `Daily Rainfall Total (mm)` Highest 30 min Rainfall (mm…¹\n  <chr>     <date>                           <dbl>                         <dbl>\n1 Admiralty 2018-01-01                         7.6                           3.1\n2 Admiralty 2018-01-02                         6.7                           2.9\n3 Admiralty 2018-01-03                        13.6                           5.2\n4 Admiralty 2018-01-04                        12.5                           5.2\n5 Admiralty 2018-01-05                         5                             2  \n6 Admiralty 2018-01-06                         0                             0  \n# ℹ abbreviated name: ¹​`Highest 30 min Rainfall (mm)`\n# ℹ 7 more variables: `Highest 60 min Rainfall (mm)` <dbl>,\n#   `Highest 120 min Rainfall (mm)` <dbl>, `Mean Temperature (Celsius)` <dbl>,\n#   `Maximum Temperature (Celsius)` <dbl>,\n#   `Minimum Temperature (Celsius)` <dbl>, `Mean Wind Speed (km/h)` <dbl>,\n#   `Max Wind Speed (km/h)` <dbl>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter specific station\n\nadmiralty_ts <- weather_ts %>%\n  filter(Station == \"Admiralty\") %>%\n  arrange(date)\n\nhead(admiralty_ts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 11\n  Station   date       `Daily Rainfall Total (mm)` Highest 30 min Rainfall (mm…¹\n  <chr>     <date>                           <dbl>                         <dbl>\n1 Admiralty 2018-01-01                         7.6                           3.1\n2 Admiralty 2018-01-01                         8.1                           4.8\n3 Admiralty 2018-01-01                         0                             0  \n4 Admiralty 2018-01-01                         1.1                           1.1\n5 Admiralty 2018-01-01                        16.9                           5.5\n6 Admiralty 2018-01-01                        19.7                          11.4\n# ℹ abbreviated name: ¹​`Highest 30 min Rainfall (mm)`\n# ℹ 7 more variables: `Highest 60 min Rainfall (mm)` <dbl>,\n#   `Highest 120 min Rainfall (mm)` <dbl>, `Mean Temperature (Celsius)` <dbl>,\n#   `Maximum Temperature (Celsius)` <dbl>,\n#   `Minimum Temperature (Celsius)` <dbl>, `Mean Wind Speed (km/h)` <dbl>,\n#   `Max Wind Speed (km/h)` <dbl>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot Daily Rainfall and Temperature\n\n\n# Plot Daily Rainfall\nggplot(admiralty_ts, aes(x = date, y = `Daily Rainfall Total (mm)`)) +\n  geom_line(color = \"steelblue\") +\n  labs(title = \"Daily Rainfall Total at Admiralty Station\",\n       x = \"Date\",\n       y = \"Rainfall (mm)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-10-1.png){width=1152}\n:::\n\n```{.r .cell-code}\n# Plot Mean Temperature\nggplot(admiralty_ts, aes(x = date, y = `Mean Temperature (Celsius)`)) +\n  geom_line(color = \"tomato\") +\n  labs(title = \"Mean Temperature at Admiralty Station\",\n       x = \"Date\",\n       y = \"Temperature (°C)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-10-2.png){width=1152}\n:::\n:::\n\n\n\n\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Preparing data for forecasting\n\n\n# Select relevant columns for forecasting (Rainfall and Temperature)\nforecast_data <- admiralty_ts %>%\n  select(date, `Daily Rainfall Total (mm)`, `Mean Temperature (Celsius)`)\n\n# Check for missing dates or data gaps\nforecast_data <- forecast_data %>%\n  complete(date = seq(min(date), max(date), by = \"day\")) %>%\n  arrange(date)\n\n# Impute missing values if necessary (e.g., using interpolation)\nforecast_data <- forecast_data %>%\n  fill(`Daily Rainfall Total (mm)`, .direction = \"downup\") %>%\n  fill(`Mean Temperature (Celsius)`, .direction = \"downup\")\n\nhead(forecast_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  date       `Daily Rainfall Total (mm)` `Mean Temperature (Celsius)`\n  <date>                           <dbl>                        <dbl>\n1 2018-01-01                         7.6                         26.5\n2 2018-01-01                         8.1                         27.5\n3 2018-01-01                         0                           29.2\n4 2018-01-01                         1.1                         30  \n5 2018-01-01                        16.9                         27.3\n6 2018-01-01                        19.7                         27.1\n```\n\n\n:::\n:::\n\n\n\n# EDA\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Simple line plot for visualization\nforecast_data %>% \n  ggplot(aes(x = date, y = `Daily Rainfall Total (mm)`)) +\n  geom_line() +\n  labs(title = \"Daily Rainfall Time Series\",\n       x = \"Date\", y = \"Rainfall (mm)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-12-1.png){width=1152}\n:::\n\n```{.r .cell-code}\n# Monthly average plot\nforecast_data %>%\n  mutate(month = floor_date(date, \"month\")) %>%\n  group_by(month) %>%\n  summarise(avg_rainfall = mean(`Daily Rainfall Total (mm)`, na.rm = TRUE)) %>%\n  ggplot(aes(x = month, y = avg_rainfall)) +\n  geom_line() +\n  labs(title = \"Monthly Average Rainfall\",\n       x = \"Month\", y = \"Avg Rainfall (mm)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-12-2.png){width=1152}\n:::\n:::\n\n\n\n# CDA\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(forecast)\n\n# Create a ts object for rainfall (assuming daily frequency)\nrainfall_ts <- ts(forecast_data$`Daily Rainfall Total (mm)`,\n                  frequency = 365,  # daily data\n                  start = c(year(min(forecast_data$date)), yday(min(forecast_data$date))))\n\n# Classical Decomposition\nrainfall_decomp <- stl(rainfall_ts, s.window = \"periodic\")\nplot(rainfall_decomp)\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-13-1.png){width=1152}\n:::\n:::\n\n\n\n# Modelling and Forecasting  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit ARIMA model\nrainfall_arima <- auto.arima(rainfall_ts)\n\n# Check summary\nsummary(rainfall_arima)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: rainfall_ts \nARIMA(0,1,0) \n\nsigma^2 = 60.25:  log likelihood = -52858.4\nAIC=105718.8   AICc=105718.8   BIC=105726.4\n\nTraining set error measures:\n                       ME     RMSE      MAE  MPE MAPE      MASE        ACF1\nTraining set 0.0005122425 7.761689 1.687299 -Inf  Inf 0.1539936 0.000276127\n```\n\n\n:::\n\n```{.r .cell-code}\n# Forecast next 30 days\nrainfall_forecast <- forecast(rainfall_arima, h = 30)\n\n# Plot forecast\nautoplot(rainfall_forecast) + \n  labs(title = \"30-Day Rainfall Forecast\",\n       x = \"Date\", y = \"Rainfall (mm)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-14-1.png){width=1152}\n:::\n:::\n\n\n\n# Evaluation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(rainfall_forecast)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                       ME     RMSE      MAE  MPE MAPE      MASE        ACF1\nTraining set 0.0005122425 7.761689 1.687299 -Inf  Inf 0.1539936 0.000276127\n```\n\n\n:::\n:::\n",
    "supporting": [
      "Take-home_Ex03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}